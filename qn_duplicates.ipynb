{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set random seeds\n",
    "rnd.seed(34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question pairs:  404351\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"questions.csv\")\n",
    "N = len(data)\n",
    "print('Number of question pairs: ', N)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 300000 Test set: 10240\n"
     ]
    }
   ],
   "source": [
    "N_train = 300000\n",
    "N_test = 10240\n",
    "data_train = data[:N_train]\n",
    "data_test = data[N_train:N_train + N_test]\n",
    "print(\"Train set:\", len(data_train), \"Test set:\", len(data_test))\n",
    "del (data)  # remove to free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate questions:  111486\n",
      "Indexes of first ten duplicate questions: [5, 7, 11, 12, 13, 15, 16, 18, 20, 29]\n"
     ]
    }
   ],
   "source": [
    "td_index = data_train['is_duplicate'] == 1\n",
    "td_index = [i for i, x in enumerate(td_index) if x]\n",
    "print('Number of duplicate questions: ', len(td_index))\n",
    "print('Indexes of first ten duplicate questions:', td_index[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
      "I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n",
      "is_duplicate:  1\n"
     ]
    }
   ],
   "source": [
    "print(data_train['question1'][5])\n",
    "print(data_train['question2'][5])\n",
    "print('is_duplicate: ', data_train['is_duplicate'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_train = np.array(data_train['question1'][td_index])\n",
    "Q2_train = np.array(data_train['question2'][td_index])\n",
    "\n",
    "Q1_test = np.array(data_test['question1'])\n",
    "Q2_test = np.array(data_test['question2'])\n",
    "y_test  = np.array(data_test['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING QUESTIONS:\n",
      "\n",
      "Question 1:  Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
      "Question 2:  I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me? \n",
      "\n",
      "Question 1:  What would a Trump presidency mean for current international masterâ€™s students on an F1 visa?\n",
      "Question 2:  How will a Trump presidency affect the students presently in US or planning to study in US? \n",
      "\n",
      "TESTING QUESTIONS:\n",
      "\n",
      "Question 1:  How do I prepare for interviews for cse?\n",
      "Question 2:  What is the best way to prepare for cse? \n",
      "\n",
      "is_duplicate = 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING QUESTIONS:\\n')\n",
    "print('Question 1: ', Q1_train[0])\n",
    "print('Question 2: ', Q2_train[0], '\\n')\n",
    "print('Question 1: ', Q1_train[5])\n",
    "print('Question 2: ', Q2_train[5], '\\n')\n",
    "\n",
    "print('TESTING QUESTIONS:\\n')\n",
    "print('Question 1: ', Q1_test[0])\n",
    "print('Question 2: ', Q2_test[0], '\\n')\n",
    "print('is_duplicate =', y_test[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate questions:  111486\n",
      "The length of the training set is:   89188\n",
      "The length of the validation set is:  22298\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data\n",
    "cut_off = int(len(Q1_train) * 0.8)\n",
    "train_Q1, train_Q2 = Q1_train[:cut_off], Q2_train[:cut_off]\n",
    "val_Q1, val_Q2 = Q1_train[cut_off:], Q2_train[cut_off:]\n",
    "print('Number of duplicate questions: ', len(Q1_train))\n",
    "print(\"The length of the training set is:  \", len(train_Q1))\n",
    "print(\"The length of the validation set is: \", len(val_Q1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning question encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "text_vectorization = tf.keras.layers.TextVectorization(output_mode='int',split='whitespace', standardize='strip_punctuation')\n",
    "text_vectorization.adapt(np.concatenate((Q1_train,Q2_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 36224\n"
     ]
    }
   ],
   "source": [
    "print(f'Vocabulary size: {text_vectorization.vocabulary_size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first question in the train set:\n",
      "\n",
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me? \n",
      "\n",
      "encoded version:\n",
      "tf.Tensor(\n",
      "[ 6984     6   178    10  8988  2442 35393   761    13  6636 28205    31\n",
      "    28   483    45    98], shape=(16,), dtype=int64) \n",
      "\n",
      "first question in the test set:\n",
      "\n",
      "How do I prepare for interviews for cse? \n",
      "\n",
      "encoded version:\n",
      "tf.Tensor([    4     8     6   160    17  2079    17 11775], shape=(8,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print('first question in the train set:\\n')\n",
    "print(Q1_train[0], '\\n') \n",
    "print('encoded version:')\n",
    "print(text_vectorization(Q1_train[0]),'\\n')\n",
    "\n",
    "print('first question in the test set:\\n')\n",
    "print(Q1_test[0], '\\n')\n",
    "print('encoded version:')\n",
    "print(text_vectorization(Q1_test[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Siamese model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Siamese Network \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Siamese(text_vectorizer, vocab_size=36224, d_feature=128):\n",
    "    \n",
    "    branch = tf.keras.models.Sequential(name='sequential') \n",
    "\n",
    "    # Add the text_vectorizer layer \n",
    "    branch.add(text_vectorizer)\n",
    "\n",
    "    # Add the Embedding layer\n",
    "    branch.add(tf.keras.layers.Embedding(input_dim = vocab_size, output_dim = d_feature, name = \"embedding\"))\n",
    "    \n",
    "    # Add the LSTM layer\n",
    "    branch.add(tf.keras.layers.LSTM(units = d_feature, return_sequences = True, name = \"LSTM\"))\n",
    "    \n",
    "    # Add the GlobalAveragePooling1D layer\n",
    "    branch.add(tf.keras.layers.GlobalAveragePooling1D(name = \"mean\"))\n",
    "    \n",
    "    # Add the normalizing layer using the Lambda function\n",
    "    branch.add(tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x), name = \"out\"))\n",
    "    \n",
    "    # Define both inputs \n",
    "    input1 = tf.keras.layers.Input((1,), dtype=tf.string, name='input_1')\n",
    "    input2 = tf.keras.layers.Input((1,), dtype=tf.string, name='input_2')\n",
    "    \n",
    "    # Define the output of each branch of your Siamese network \n",
    "    branch1 = branch(input1)\n",
    "    branch2 = branch(input2)\n",
    "\n",
    "    # Define the Concatenate layer \n",
    "    conc = tf.keras.layers.Concatenate(axis=1, name='conc_1_2')([branch1, branch2])\n",
    "        \n",
    "    return tf.keras.models.Model(inputs=[input1, input2], outputs=conc, name=\"SiameseModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseModel\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 128)          4768256     ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conc_1_2 (Concatenate)         (None, 256)          0           ['sequential[0][0]',             \n",
      "                                                                  'sequential[1][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,768,256\n",
      "Trainable params: 4,768,256\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, None)             0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 128)         4636672   \n",
      "                                                                 \n",
      " LSTM (LSTM)                 (None, None, 128)         131584    \n",
      "                                                                 \n",
      " mean (GlobalAveragePooling1  (None, 128)              0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " out (Lambda)                (None, 128)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,768,256\n",
      "Trainable params: 4,768,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# check model\n",
    "model = Siamese(text_vectorization, vocab_size=text_vectorization.vocabulary_size())\n",
    "model.build(input_shape=None)\n",
    "model.summary()\n",
    "model.get_layer(name='sequential').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=True,\n",
    "    show_dtype=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
